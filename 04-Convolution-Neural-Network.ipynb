{
 "metadata": {
  "name": "",
  "signature": "sha256:72bf351a74eb038a5debcb3e6ec2882b7104226c3eab7fc666c2cfcded85c28b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cs231n.data_utils import load_CIFAR10\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
      "  \"\"\"\n",
      "  Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
      "  it for the linear classifier. These are the same steps as we used for the\n",
      "  SVM, but condensed to a single function.  \n",
      "  \"\"\"\n",
      "  # Load the raw CIFAR-10 data\n",
      "  cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
      "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
      "  \n",
      "  # subsample the data\n",
      "  mask = range(num_training, num_training + num_validation)\n",
      "  X_val = X_train[mask]\n",
      "  y_val = y_train[mask]\n",
      "  mask = range(num_training)\n",
      "  X_train = X_train[mask]\n",
      "  y_train = y_train[mask]\n",
      "  mask = range(num_test)\n",
      "  X_test = X_test[mask]\n",
      "  y_test = y_test[mask]\n",
      "  \n",
      "  # Preprocessing: reshape the image data into rows\n",
      "  X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
      "  X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
      "  X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
      "  \n",
      "  # Normalize the data: subtract the mean image\n",
      "  mean_image = np.mean(X_train, axis = 0)\n",
      "  \n",
      "  # add bias dimension and transform into columns\n",
      "  #X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]).T\n",
      "  #X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]).T\n",
      "  #X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]).T\n",
      "  \n",
      "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
      "\n",
      "\n",
      "# Invoke the above function to get our data.\n",
      "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
      "print 'Train data shape: ', X_train.shape\n",
      "print 'Train labels shape: ', y_train.shape\n",
      "print 'Validation data shape: ', X_val.shape\n",
      "print 'Validation labels shape: ', y_val.shape\n",
      "print 'Test data shape: ', X_test.shape\n",
      "print 'Test labels shape: ', y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train data shape:  (49000, 3072)\n",
        "Train labels shape:  (49000,)\n",
        "Validation data shape:  (1000, 3072)\n",
        "Validation labels shape:  (1000,)\n",
        "Test data shape:  (1000, 3072)\n",
        "Test labels shape:  (1000,)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def one_hot(x,n):\n",
      "    if type(x) == list: x = np.array(x)\n",
      "    x = x.flatten()\n",
      "    o_h = np.zeros((len(x),n))\n",
      "    o_h[np.arange(len(x)),x] = 1\n",
      "    return o_h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_o_h = one_hot(y_train,10)\n",
      "y_val_o_h = one_hot(y_val,10)\n",
      "y_test_o_h = one_hot(y_test,10)\n",
      "print 'Train labels shape: ', y_train_o_h.shape\n",
      "print 'Train labels shape: ', y_val_o_h.shape\n",
      "print 'Train labels shape: ', y_test_o_h.shape\n",
      "\n",
      "X_train = X_train.reshape(-1,3,32,32)\n",
      "X_val = X_val.reshape(-1,3,32,32)\n",
      "X_test = X_test.reshape(-1,3,32,32)\n",
      "\n",
      "print 'Train data shape: ', X_train.shape\n",
      "print 'Validation data shape: ', X_val.shape\n",
      "print 'Test data shape: ', X_test.shape\n",
      "    \n",
      "'''\n",
      "X_train_t = np.transpose(X_train)\n",
      "X_val_t = np.transpose(X_val)\n",
      "X_test_t = np.transpose(X_test)\n",
      "print 'Train data shape: ', X_train_t.shape\n",
      "print 'Validation data shape: ', X_val_t.shape\n",
      "print 'Test data shape: ', X_test_t.shape\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train labels shape:  (49000, 10)\n",
        "Train labels shape:  (1000, 10)\n",
        "Train labels shape:  (1000, 10)\n",
        "Train data shape:  (49000, 3, 32, 32)\n",
        "Validation data shape:  (1000, 3, 32, 32)\n",
        "Test data shape:  (1000, 3, 32, 32)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "\"\\nX_train_t = np.transpose(X_train)\\nX_val_t = np.transpose(X_val)\\nX_test_t = np.transpose(X_test)\\nprint 'Train data shape: ', X_train_t.shape\\nprint 'Validation data shape: ', X_val_t.shape\\nprint 'Test data shape: ', X_test_t.shape\\n\""
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "from theano import tensor as T\n",
      "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
      "import numpy as np\n",
      "from theano.tensor.nnet.conv import conv2d\n",
      "from theano.tensor.signal.downsample import max_pool_2d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srng = RandomStreams()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def floatX(X):\n",
      "    return np.asarray(X, dtype=theano.config.floatX)\n",
      "\n",
      "def init_weights(shape, factor=0.00005):\n",
      "    return theano.shared(floatX(np.random.randn(*shape) * factor))\n",
      "\n",
      "def rectify(X):\n",
      "    return T.maximum(X, 0.0)\n",
      "\n",
      "def softmax(X):\n",
      "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
      "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
      "\n",
      "def dropout(X, p=0.0):\n",
      "    if p > 0:\n",
      "        retain_prob = 1 - p\n",
      "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
      "        X /= retain_prob\n",
      "    return X\n",
      "\n",
      "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
      "    grads = T.grad(cost=cost, wrt=params)\n",
      "    updates = []\n",
      "    for p, g in zip(params, grads):\n",
      "        acc = theano.shared(p.get_value() * 0.0)\n",
      "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
      "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
      "        g = g / gradient_scaling\n",
      "        updates.append((acc, acc_new))\n",
      "        updates.append((p, p - lr * g))\n",
      "    return updates\n",
      "\n",
      "def model(X, w, w2, w3, w4, p_drop_conv, p_drop_hidden):\n",
      "    l1a = rectify(conv2d(X, w, border_mode='full'))\n",
      "    l1 = max_pool_2d(l1a, (2, 2))\n",
      "    l1 = dropout(l1, p_drop_conv)\n",
      "\n",
      "    l2a = rectify(conv2d(l1, w2))\n",
      "    l2 = max_pool_2d(l2a, (2, 2))\n",
      "    l2 = dropout(l2, p_drop_conv)\n",
      "\n",
      "    l3a = rectify(conv2d(l2, w3))\n",
      "    l3b = max_pool_2d(l3a, (2, 2))\n",
      "    l3 = T.flatten(l3b, outdim=2)\n",
      "    l3 = dropout(l3, p_drop_conv)\n",
      "\n",
      "    l4 = rectify(T.dot(l3, w4))\n",
      "    l4 = dropout(l4, p_drop_hidden)\n",
      "\n",
      "    pyx = softmax(T.dot(l4, w_o))\n",
      "    return l1, l2, l3, l4, pyx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "32 * 32 * 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "3072"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = T.ftensor4()\n",
      "Y = T.fmatrix()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w = init_weights((32, 3, 3, 3))\n",
      "w2 = init_weights((64, 32, 3, 3))\n",
      "w3 = init_weights((128, 64, 3, 3))\n",
      "w4 = init_weights((128 * 3 * 3, 625))\n",
      "w_o = init_weights((625, 10))\n",
      "\n",
      "noise_l1, noise_l2, noise_l3, noise_l4, noise_py_x = model(X, w, w2, w3, w4, 0.2, 0.5)\n",
      "l1, l2, l3, l4, py_x = model(X, w, w2, w3, w4, 0., 0.)\n",
      "y_x = T.argmax(py_x, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/theano/sandbox/rng_mrg.py:1195: UserWarning: MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 60*256\n",
        "  nstreams = self.n_streams(size)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
      "params = [w, w2, w3, w4, w_o]\n",
      "updates = RMSprop(cost, params, lr=0.001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
      "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Initial Error:\", np.mean(np.argmax(y_val_o_h, axis=1) == predict(X_val))\n",
      "for i in range(100):\n",
      "    for start, end in zip(range(0, len(X_train), 128), range(128, len(X_train), 128)):\n",
      "        cost = train(X_train[start:end], y_train_o_h[start:end])\n",
      "    print i, np.mean(np.argmax(y_val_o_h, axis=1) == predict(X_val))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Initial Error: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.083\n",
        "0"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}